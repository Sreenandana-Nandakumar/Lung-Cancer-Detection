{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","from glob import glob\n","\n","import cv2\n","import os\n","import gc\n","\n","import sklearn\n","from sklearn.model_selection import train_test_split\n","from sklearn import metrics\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from keras import layers\n","\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from zipfile import ZipFile\n","\n","# Path to the zip file\n","data_path = 'lung-and-colon-cancer-histopathological-images.zip'\n","\n","# Extract the contents of the zip file\n","with ZipFile(data_path, 'r') as zip:\n","    zip.extractall()  # Extract all files and directories to the current working directory\n","    print('The data set has been extracted.')\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Data Visualization"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Set the path to the directory containing the lung image sets\n","path = '/kaggle/input/lung-and-colon-cancer-histopathological-images/lung_colon_image_set/lung_image_sets'\n","\n","# Get the list of classes (subdirectories) in the specified path\n","classes = os.listdir(path)\n","\n","# Print the list of classes\n","print(classes)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["path = '/kaggle/input/lung-and-colon-cancer-histopathological-images/lung_colon_image_set/lung_image_sets'\n","\n","# Iterate over each category\n","for cat in classes:\n","    image_dir = f'{path}/{cat}'\n","    images = os.listdir(image_dir)\n","    \n","    # Create a figure with 3 subplots\n","    fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n","    fig.suptitle(f'Images for {cat} category . . . .', fontsize=20)\n","    \n","    # Display 3 random images from the category\n","    for i in range(3):\n","        k = np.random.randint(0, len(images))\n","        img = np.array(Image.open(f'{path}/{cat}/{images[k]}'))\n","        \n","        # Show the image on the subplot\n","        ax[i].imshow(img)\n","        ax[i].axis('off')\n","    \n","    plt.show()  # Show the plot with the images\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Data Preparation for Training"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Set the image size for resizing images\n","IMG_SIZE = 256\n","\n","# Set the split ratio for train-test split\n","SPLIT = 0.2\n","\n","# Set the number of epochs for training\n","EPOCHS = 10\n","\n","# Set the batch size for training\n","BATCH_SIZE = 64"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Create empty lists to store the data\n","X = []\n","Y = []\n","\n","# Loop over each category\n","for i, cat in enumerate(classes):\n","    # Get a list of image paths for the current category\n","    images = glob(f'{path}/{cat}/*.jpeg')\n","\n","    # Loop over each image in the current category\n","    for image in images:\n","        # Read the image using OpenCV\n","        img = cv2.imread(image)\n","\n","        # Resize the image to the desired size (IMG_SIZE)\n","        resized_img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n","\n","        # Append the resized image to the X list\n","        X.append(resized_img)\n","\n","        # Append the category index (i) to the Y list\n","        Y.append(i)\n","\n","# Convert X list to a NumPy array\n","X = np.asarray(X)\n","\n","# Perform one-hot encoding on Y using pandas get_dummies function\n","one_hot_encoded_Y = pd.get_dummies(Y).values"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Splitting the data into training and validation sets using train_test_split\n","X_train, X_val, Y_train, Y_val = train_test_split(X, one_hot_encoded_Y,\n","                                                  test_size=SPLIT,\n","                                                  random_state=2022)\n","\n","# Printing the shapes of the training and validation sets\n","print(\"Training set shape:\", X_train.shape)\n","print(\"Validation set shape:\", X_val.shape)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Model Development"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model = keras.models.Sequential([\n","    # First convolutional layer\n","    layers.Conv2D(\n","        filters=32,\n","        kernel_size=(5, 5),\n","        activation='relu',\n","        input_shape=(IMG_SIZE, IMG_SIZE, 3),\n","        padding='same'\n","    ),\n","    layers.MaxPooling2D(2, 2),  # Max pooling layer\n"," \n","    # Second convolutional layer\n","    layers.Conv2D(\n","        filters=64,\n","        kernel_size=(3, 3),\n","        activation='relu',\n","        padding='same'\n","    ),\n","    layers.MaxPooling2D(2, 2),  # Max pooling layer\n"," \n","    # Third convolutional layer\n","    layers.Conv2D(\n","        filters=128,\n","        kernel_size=(3, 3),\n","        activation='relu',\n","        padding='same'\n","    ),\n","    layers.MaxPooling2D(2, 2),  # Max pooling layer\n"," \n","    layers.Flatten(),  # Flatten the output of the previous layer\n"," \n","    layers.Dense(256, activation='relu'),  # Fully connected layer\n","    layers.BatchNormalization(),  # Batch normalization layer\n"," \n","    layers.Dense(128, activation='relu'),  # Fully connected layer\n","    layers.Dropout(0.3),  # Dropout layer to prevent overfitting\n","    layers.BatchNormalization(),  # Batch normalization layer\n"," \n","    layers.Dense(3, activation='softmax')  # Output layer with softmax activation\n","])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Plot the model architecture\n","keras.utils.plot_model(\n","    model,  # The Keras model object to be plotted\n","    show_shapes=True,  # Flag to show the shapes of the layers\n","    show_dtype=True,  # Flag to show the data types of the layers\n","    show_layer_activations=True  # Flag to show the activations of the layers\n",")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Karan.. ith entha ingane enn areela... ellam download okke aaki still preshnam"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model.compile(\n","    optimizer='adam',  # Optimizer used for training the model\n","    loss='categorical_crossentropy',  # Loss function used for training\n","    metrics=['accuracy']  # Evaluation metrics used during training\n",")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Callback"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n","\n","# Custom callback to stop training when validation accuracy reaches 90%\n","class myCallback(tf.keras.callbacks.Callback):\n","    def on_epoch_end(self, epoch, logs={}):\n","        if logs.get('val_accuracy') > 0.90:\n","            print('\\nValidation accuracy has reached 90%, stopping further training.')\n","            self.model.stop_training = True\n","\n","# Early stopping callback to stop training if validation accuracy does not improve for 3 consecutive epochs\n","es = EarlyStopping(\n","    patience=3,\n","    monitor='val_accuracy',\n","    restore_best_weights=True\n",")\n","\n","# Reduce learning rate on plateau callback to reduce learning rate if validation loss does not improve for 2 consecutive epochs\n","lr = ReduceLROnPlateau(\n","    monitor='val_loss',\n","    patience=2,\n","    factor=0.5,\n","    verbose=1\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["history = model.fit(X_train, Y_train,\n","                    validation_data = (X_val, Y_val),\n","                    batch_size = BATCH_SIZE,\n","                    epochs = EPOCHS,\n","                    verbose = 1,\n","                    callbacks = [es, lr, myCallback()])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Convert the history dictionary to a DataFrame\n","history_df = pd.DataFrame(history.history)\n","\n","# Plot the training and validation loss\n","plt.figure(figsize=(10, 6))\n","history_df.loc[:, ['loss', 'val_loss']].plot()\n","plt.title('Training and Validation Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.legend(['Training Loss', 'Validation Loss'])\n","plt.grid(True)\n","plt.show()\n","\n","# Plot the training and validation accuracy\n","plt.figure(figsize=(10, 6))\n","history_df.loc[:, ['accuracy', 'val_accuracy']].plot()\n","plt.title('Training and Validation Accuracy')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.legend(['Training Accuracy', 'Validation Accuracy'])\n","plt.grid(True)\n","plt.show()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Model Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Make predictions on validation data\n","Y_pred = model.predict(X_val)\n","\n","# Convert true labels to their corresponding class indices\n","Y_val = np.argmax(Y_val, axis=1)\n","\n","# Convert predicted labels to their corresponding class indices\n","Y_pred = np.argmax(Y_pred, axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["confusion_matrix = metrics.confusion_matrix(Y_val, Y_pred)\n","\n","df_confusion_matrix = pd.DataFrame(confusion_matrix)\n","\n","# Set the axis labels\n","df_confusion_matrix.index.name = 'Actual'\n","df_confusion_matrix.columns.name = 'Predicted'\n","\n","print(df_confusion_matrix)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Print the classification report\n","report = metrics.classification_report(Y_val, Y_pred, target_names=classes)\n","print(report)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat":4,"nbformat_minor":5}
