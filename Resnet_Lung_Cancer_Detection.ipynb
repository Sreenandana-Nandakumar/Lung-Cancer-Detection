{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","from glob import glob\n","import sklearn\n","import cv2\n","import gc\n","import os\n","\n","import tensorflow as tf\n","from tensorflow.keras.applications import ResNet50\n","from tensorflow import keras\n","from keras import layers\n","from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn import metrics\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Specify the path where the classes (subdirectories) are located\n","path = '/kaggle/input/lung-and-colon-cancer-histopathological-images/lung_colon_image_set/lung_image_sets'\n","\n","# Use the os.listdir() function to list the subdirectories (classes) in the specified path\n","classes = os.listdir(path)\n","\n","# Print the list of classes\n","print(classes)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Iterate over each category (subdirectory) in the classes list\n","for category in classes:\n","    # Define the image directory path for the current category\n","    image_dir = f'{path}/{category}'\n","    \n","    # List all the image files in the image directory\n","    images = os.listdir(image_dir)\n","\n","    # Create a figure with three subplots for displaying the images\n","    fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n","    # Set the title for the figure\n","    fig.suptitle(f'Images for {category} category . . . .', fontsize=20)\n","\n","    # Iterate three times to display three random images from the category\n","    for i in range(3):\n","        # Generate a random index within the range of the number of images in the category\n","        k = np.random.randint(0, len(images))\n","        # Read the image using PIL and convert it to a NumPy array\n","        img = np.array(Image.open(f'{path}/{category}/{images[k]}'))\n","        # Display the image in the corresponding subplot\n","        ax[i].imshow(img)\n","        ax[i].axis('off')\n","    \n","    # Show the figure with the three images for the current category\n","    plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#Images will be resized to this size before being fed to the model\n","IMG_SIZE = 256\n","\n","#testing: 20% and training: 80%\n","SPLIT = 0.2\n","\n","#CNN model will iterate 10 times over the entire training dataset during the training process\n","#Epoch: each iteration over the full dataset\n","EPOCHS = 10\n","\n","#no of samples that will be processed by the CNN model in a single forward and backward pass.\n","BATCH_SIZE = 64"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#stores preprocessed image data\n","X = []\n","#stores corresponding labels\n","Y = []\n","\n","#i: index, category: element\n","for i, category in enumerate(classes):\n","  #The glob function returns a list of filenames that match the path\n","    images = glob(f'{path}/{category}/*.jpeg')\n","    count = 0\n","    \n","\n","    for image in images:\n","        # Stop processing images for this category if 1500 images are already processed\n","        if count >= 2000:\n","            break  \n","        #loads image as numpy array in 'img'\n","        img = cv2.imread(image)\n","\n","        #resizes image and appends to the array X\n","        X.append(cv2.resize(img, (IMG_SIZE, IMG_SIZE)))\n","        #append category index of current image to Y\n","        Y.append(i)\n","        \n","        count += 1\n","\n","#converts X into numpy array.\n","X = np.asarray(X)\n","\n","#each label in Y is one hot encoded in a binary vector and the resulting list is converted to a numpy array\n","one_hot_encoded_Y = pd.get_dummies(Y).values"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#splitting into testing and training set\n","X_train, X_val, Y_train, Y_val = train_test_split(\n","    X, one_hot_encoded_Y,\n","    test_size = SPLIT,\n","    #ensures that each time the programming is run, the splitting is the same\n","    random_state = 2022\n",")\n","print(X_train.shape, X_val.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Defining the base model\n","base_model = ResNet50(\n","    # Fully connected layer on top of the network should not be included\n","    include_top=False, \n","    weights=\"imagenet\",\n","    # 3: colour channels RGB\n","    input_shape=(IMG_SIZE, IMG_SIZE, 3), \n","    # Pooling layers downsample the input by dividing the input's spatial dimensions into smaller regions and summarizing each region into a single value.\n","    # Convolutional layers will be averaged spatially before being passed to the next layers\n","    pooling='avg'\n",")\n","\n","# Create the model architecture by adding layers on top of the pre-trained ResNet50 base model\n","model = keras.models.Sequential(\n","    [\n","        # Base model is added as first layer\n","        base_model,\n","        # Dense layer: every neuron in the layer is connected to every neuron in the previous layer and produces o/p that acts as i/p to the next layer\n","        # Adds a fully connected layer with 256 units and ReLU activation function\n","        layers.Dense(256, activation='relu'),\n","        # Normalize the inputs to the next layer\n","        layers.BatchNormalization(),\n","        layers.Dense(128, activation='relu'),\n","        # Randomly sets 30% of the inputs to 0 during training to avoid overfitting\n","        layers.Dropout(0.3),\n","        layers.BatchNormalization(),\n","        # Adds the output layer with a number of units equal to the number of classes in the dataset\n","        # Softmax produces probability scores for each class\n","        layers.Dense(len(classes), activation='softmax')\n","    ]\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Generates a diagram that illustrates the structure and connectivity of the model's layers\n","keras.utils.plot_model(\n","    model,\n","    show_shapes=True,\n","    show_dtype=True,\n","    show_layer_activations=True\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Used to configure the model for training\n","model.compile(\n","    # Specifies the algorithm used to update the weights of the model during training should be adam\n","    optimizer=keras.optimizers.Adam(\n","        learning_rate = 1e-3, beta_1 = 0.9, beta_2 = 0.999, amsgrad = False\n","    ),\n","    # Categorical_crossentropy is usually used where the target variable is one-hot encoded\n","    loss='categorical_crossentropy',\n","    metrics=['accuracy']\n",")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class CustomStop(tf.keras.callbacks.Callback):\n","    def check_validation_accuracy(self, epoch, logs={}):\n","        # Checks if the validation accuracy has reached a threshold of 90%, after which it stops training\n","        if logs.get('val_accuracy') > 0.97:\n","            print('\\n Validation accuracy has reached up to 97%, stopping further training.')\n","            self.model.stop_training = True\n","\n","# Waits for 3 epochs before stopping training if there are no improvements and picks weights of the best performing epoch before stopping training.\n","early_stopping = EarlyStopping(\n","    patience=3,\n","    monitor='val_accuracy',\n","    restore_best_weights=True\n",")\n","\n","# Learning rate is reduced by a factor of 0.5 when there has been no improvements for 2 epochs\n","reduce_learning_rate = ReduceLROnPlateau(\n","    monitor='val_loss',\n","    patience=2,\n","    factor=0.5,\n","    verbose=1\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Trains the model using the specified parameters and callbacks\n","history = model.fit(\n","    X_train, Y_train,\n","    validation_data=(X_val, Y_val),\n","    batch_size=BATCH_SIZE,\n","    epochs=EPOCHS,\n","    verbose=1,\n","    callbacks=[early_stopping, reduce_learning_rate, CustomStop()]\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Creates a dataframe history_df where the history object contains the training history, including the loss and metrics values at each epoch\n","history_df = pd.DataFrame(history.history)\n","# Plotting training and validation loss\n","history_df.loc[:, ['loss', 'val_loss']].plot()\n","# Plotting training and validation accuracy\n","history_df.loc[:, ['accuracy', 'val_accuracy']].plot()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["Y_pred = model.predict(X_val)\n","# Convert one-hot encoded format to their original form\n","Y_val = np.argmax(Y_val, axis=1)\n","Y_pred = np.argmax(Y_pred, axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Print confusion matrix\n","print(metrics.confusion_matrix(Y_val, Y_pred))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["print(metrics.classification_report(Y_val, Y_pred, target_names=classes))"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat":4,"nbformat_minor":4}
